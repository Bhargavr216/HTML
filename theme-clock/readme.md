```
UNIT I | Q1: WHAT IS MACHINE LEARNING?
Machine Learning enables computers to learn patterns from data without explicit programming. Systems improve performance through experience rather than hardcoded rules.

ğŸ”¹ Definition (4 words)
Learning from data automatically

ğŸ”¹ Core Concept
Data + Algorithm â†’ Model â†’ Predictions

ğŸ”¹ Importance (4 words)
Automates complex decision making

ğŸ”¹ Real Examples
â€¢ Healthcare: Disease prediction
â€¢ Finance: Fraud detection
â€¢ E-commerce: Recommendations

UNIT I | Q2: TYPES OF ML LEARNING
Four learning types based on data availability and feedback mechanism.

ğŸ”¹ Supervised Learning (4 words)
Labeled data input-output pairs
â†’ Classification & Regression
â†’ Algorithms: Decision Trees, SVM

ğŸ”¹ Unsupervised Learning (4 words)
Discovers hidden patterns unlabeled
â†’ Clustering & Dimensionality Reduction
â†’ Algorithms: K-Means, PCA

ğŸ”¹ Semi-Supervised (4 words)
Small labeled + large unlabeled
â†’ Uses both data types

ğŸ”¹ Reinforcement Learning (4 words)
Agent learns via rewards
â†’ Trial-and-error decision making
â†’ Algorithms: Q-Learning

UNIT I | Q4: SUPERVISED LEARNING
Learning mapping function from labeled input-output examples to predict unseen data.

ğŸ”¹ How It Works (5 words)
Observe patterns â†’ Generalize â†’ Predict
Training Data â†’ Model â†’ Predictions

ğŸ”¹ Types
â€¢ Classification: Discrete output (Spam/Not Spam)
â€¢ Regression: Continuous output (House price)

ğŸ”¹ Algorithms
Logistic Regression, Decision Trees, SVM, KNN

UNIT I | Q5: REGRESSION VS CLASSIFICATION
Regression predicts continuous values; classification assigns discrete class labels.

| Aspect | Regression | Classification |
|--------|------------|----------------|
| Output | Continuous | Categorical |
| Example | â‚¹50,000 | Spam/Not Spam |
| Algorithm | Linear Regression | Logistic Regression |
| Evaluation | MSE, RMSE | Accuracy, F1-score |

UNIT I | Q7: LINEAR REGRESSION
Predicts continuous output using linear relationship between input features and target variable.

ğŸ”¹ Model Equation
y = bâ‚€ + bâ‚xâ‚ + bâ‚‚xâ‚‚ + ... + bâ‚™xâ‚™

ğŸ”¹ Assumptions (4 words)
Linearity, Independence, Homoscedasticity, Normality

ğŸ”¹ Applications
â€¢ House price prediction
â€¢ Sales forecasting
â€¢ Temperature estimation

UNIT I | Q9: LOGISTIC REGRESSION
Classification algorithm predicting probability of binary outcome using sigmoid function.

ğŸ”¹ Sigmoid Function
Ïƒ(z) = 1 / (1 + eâ»á¶»)
â†’ Output: 0 to 1 probability

ğŸ”¹ Decision Rule
Probability â‰¥ 0.5 â†’ Class 1
Probability < 0.5 â†’ Class 0

ğŸ”¹ Applications
Spam detection, Disease diagnosis, Credit scoring

UNIT II | Q3: FEATURE SELECTION IMPORTANCE
Selecting relevant features improves model accuracy, reduces overfitting, and lowers computational cost.

ğŸ”¹ Why Important (5 words)
Better accuracy, less complexity
â€¢ Removes noise & redundancy
â€¢ Handles curse of dimensionality
â€¢ Improves interpretability

ğŸ”¹ Example: House Price
âœ“ Useful: Area, Location, Rooms
âœ— Useless: Owner name, House color

UNIT II | Q4: FEATURE CONSTRUCTION & TRANSFORMATION
Creating new features or modifying existing ones to improve model performance.

| Type | Purpose | Example |
|------|---------|---------|
| Construction | Create informative features | BMI = weight/heightÂ² |
| Transformation | Scale/modify features | Normalization 0-1 range |

ğŸ”¹ Importance (4 words)
Enhances data representation quality

UNIT II | Q5: BINARY CLASSIFICATION
Classification problem with exactly two possible output classes.

ğŸ”¹ Output Labels
0/1, Yes/No, True/False

ğŸ”¹ Examples
â€¢ Spam detection (Spam/Not Spam)
â€¢ Disease diagnosis (Yes/No)
â€¢ Fraud detection (Fraud/Genuine)

ğŸ”¹ Algorithms
Logistic Regression, SVM, Decision Trees

UNIT II | Q6: EVALUATION METRICS
Metrics derived from confusion matrix to assess binary classifier performance.

ğŸ”¹ Confusion Matrix
TP  FP
FN  TN

ğŸ”¹ Key Formulas
Accuracy = (TP+TN)/(TP+TN+FP+FN)
Precision = TP/(TP+FP)
Recall = TP/(TP+FN)
F1 = 2Ã—(PrecÃ—Rec)/(Prec+Rec)

ğŸ”¹ When to Use
â€¢ Precision: Minimize false positives
â€¢ Recall: Minimize false negatives

UNIT II | Q8: UNSUPERVISED LEARNING
Learning patterns from unlabeled data without predefined output classes.

ğŸ”¹ Main Tasks (4 words)
Clustering and dimensionality reduction

ğŸ”¹ Clustering Example
Customer segmentation â†’ Groups by behavior

ğŸ”¹ Dimensionality Reduction
PCA â†’ Reduce features while preserving info

UNIT III | Q1: DECISION TREE REPRESENTATION
Tree-structured model using if-else rules for classification/regression decisions.

ğŸ”¹ Components (4 words)
Nodes, branches, leaves structure
â€¢ Root: Top decision node
â€¢ Internal: Attribute tests
â€¢ Leaf: Final class label

ğŸ”¹ Diagram
      [Outlook]
     /   |   \
 Sunny Overcast Rain
   |      |      |
[Humidity] Play [Wind]
  / \          /  \
High Normal  Weak Strong
  |    |      |     |
 No   Yes    Yes   No

UNIT III | Q2: DECISION TREE LEARNING ALGORITHM
Recursively splits data using best attribute until pure subsets achieved.

ğŸ”¹ Steps (5 steps)
1. Start with full dataset
2. Select best attribute (max IG/Gini)
3. Split data by attribute values
4. Create child nodes
5. Repeat until stopping condition

ğŸ”¹ Stopping Criteria
â€¢ All instances same class
â€¢ No attributes left
â€¢ Max depth reached

UNIT III | Q3: ID3 ALGORITHM
Decision tree algorithm using entropy and information gain for attribute selection.

ğŸ”¹ Core Concepts (4 words)
Entropy measures impurity
Entropy(S) = -Î£ páµ¢ logâ‚‚(páµ¢)
IG(S,A) = Entropy(S) - Î£(|Sáµ¥|/|S|)Â·Entropy(Sáµ¥)

ğŸ”¹ Steps
1. Calculate dataset entropy
2. Compute IG for all attributes
3. Select max IG attribute as node
4. Split data â†’ create branches
5. Repeat recursively

ğŸ”¹ Play Tennis Example
Outlook (max IG) â†’ Root node

UNIT III | Q4: DECISION TREES VS LINEAR MODELS
Decision Trees use hierarchical rules; Linear Models assume linear relationships.

| Aspect | Decision Trees | Linear Models |
|--------|----------------|---------------|
| Structure | Tree/hierarchical | Mathematical equation |
| Relationship | Non-linear | Linear only |
| Scaling | Not required | Required |
| Interpretability | Very high | Moderate |
| Overfitting | High risk | Lower risk |

UNIT III | Q5: SUPPORT VECTOR MACHINES (SVM)
Finds optimal hyperplane maximizing margin between different classes.

ğŸ”¹ Key Elements (4 words)
Hyperplane, margin, support vectors
â€¢ Hyperplane: Decision boundary
â€¢ Margin: Distance to nearest points
â€¢ Support Vectors: Critical boundary points

ğŸ”¹ Diagram
Class +1    |    Class -1
  â— â—      |      â—‹ â—‹
    â—      |    â—‹
-----------|----------- â† Optimal Hyperplane
    â—      |        â—‹

ğŸ”¹ Equation
wÂ·x + b = 0

UNIT III | Q6: KERNEL METHODS
Enables non-linear classification by mapping data to higher dimensions.

ğŸ”¹ Kernel Trick (4 words)
Implicit high-dimensional transformation
K(xâ‚,xâ‚‚) = Ï†(xâ‚)Â·Ï†(xâ‚‚) without computing Ï†

ğŸ”¹ Common Kernels
â€¢ Linear: xâ‚Â·xâ‚‚
â€¢ Polynomial: (xâ‚Â·xâ‚‚ + c)áµˆ
â€¢ RBF: e^(-Î³â€–xâ‚-xâ‚‚â€–Â²)

ğŸ”¹ Purpose (4 words)
Solve non-linear problems efficiently

UNIT III | Q7: PERCEPTRON MODEL
Single-layer neural network for binary linear classification.

ğŸ”¹ Structure
xâ‚â”€(wâ‚)â”€â”
xâ‚‚â”€(wâ‚‚)â”€â”¼â”€â–º Î£ â”€â”€â–º f(z) â”€â”€â–º Output (0/1)
xâ‚ƒâ”€(wâ‚ƒ)â”€â”˜
   + b

ğŸ”¹ Learning Rule
wáµ¢â¿áµ‰Ê· = wáµ¢áµ’Ë¡áµˆ + Î·(y - Å·)xáµ¢
bâ¿áµ‰Ê· = báµ’Ë¡áµˆ + Î·(y - Å·)

ğŸ”¹ Limitation (4 words)
Only linearly separable problems

UNIT III | Q8: DT & SVM ADVANTAGES/LIMITATIONS
Decision Trees: interpretable but unstable; SVMs: accurate but complex.

| Algorithm | Advantages | Limitations |
|-----------|------------|-------------|
| Decision Trees | â€¢ Easy interpretation<br>â€¢ Handles mixed data | â€¢ Overfitting risk<br>â€¢ Unstable to data changes |
| SVMs | â€¢ Effective high dimensions<br>â€¢ Robust to overfitting | â€¢ Computationally expensive<br>â€¢ Less interpretable |

UNIT IV | Q2: K-NEAREST NEIGHBOUR (KNN)
Classifies based on majority class of k nearest training points.

ğŸ”¹ Steps (5 steps)
1. Choose k value
2. Calculate distances (Euclidean)
3. Find k nearest neighbors
4. Count class labels
5. Assign majority class

ğŸ”¹ Distance Formula
d = âˆšÎ£(xáµ¢ - yáµ¢)Â²

ğŸ”¹ Diagram
â— â—      â—‹
  â—  x  â—‹   â† New point
â—        â—‹ â—‹
k=3 â†’ Majority â— = Class A

UNIT IV | Q3: K-MEANS CLUSTERING
Partitions data into K clusters by minimizing intra-cluster distance.

ğŸ”¹ Steps (5 steps)
1. Choose K clusters
2. Initialize K centroids randomly
3. Assign points to nearest centroid
4. Update centroids (mean of cluster)
5. Repeat until convergence

ğŸ”¹ Objective Function
J = Î£ Î£ â€–x - Î¼â‚–â€–Â² (minimize WCSS)

ğŸ”¹ Limitation (4 words)
Sensitive to initial centroids

UNIT IV | Q4: K-MEDOIDS CLUSTERING
Uses actual data points (medoids) instead of centroids as cluster centers.

ğŸ”¹ Key Difference (4 words)
Medoids = actual data points
â€¢ More robust to outliers
â€¢ Higher computational cost
â€¢ Works with any distance metric

ğŸ”¹ Algorithm: PAM
1. Select K medoids
2. Assign points to nearest medoid
3. Swap medoids to minimize cost
4. Repeat until stable

UNIT IV | Q6: NAÃVE BAYES CLASSIFIER
Probabilistic classifier using Bayes' theorem with feature independence assumption.

ğŸ”¹ Bayes' Theorem
P(C|X) = [P(X|C)Â·P(C)] / P(X)

ğŸ”¹ NaÃ¯ve Assumption
P(X|C) = P(xâ‚|C)Â·P(xâ‚‚|C)Â·...Â·P(xâ‚™|C)

ğŸ”¹ Types
â€¢ Gaussian: Continuous data
â€¢ Multinomial: Text classification
â€¢ Bernoulli: Binary features

UNIT IV | Q7: EM ALGORITHM
Iterative method for parameter estimation with hidden/missing variables.

ğŸ”¹ Two Steps (4 words)
Expectation then Maximization
E-Step: Estimate hidden variables
M-Step: Update parameters

ğŸ”¹ Applications
â€¢ Gaussian Mixture Models
â€¢ Missing data imputation
â€¢ Hidden Markov Models

UNIT IV | Q8: GAUSSIAN MIXTURE MODELS (GMM)
Represents data as mixture of multiple Gaussian distributions.

ğŸ”¹ Soft Clustering (4 words)
Probabilistic cluster membership
p(x) = Î£ Ï€â‚–Â·N(x|Î¼â‚–,Î£â‚–)

ğŸ”¹ vs K-Means
| K-Means | GMM |
|---------|-----|
| Hard clusters | Soft clusters |
| Spherical only | Elliptical shapes |
| Distance-based | Probability-based |

UNIT V | Q1: NEURAL NETWORK REPRESENTATION
Interconnected neurons organized in layers mimicking biological networks.

ğŸ”¹ Structure (3 layers)
Input â†’ Hidden â†’ Output

ğŸ”¹ Neuron Model
z = Î£ wáµ¢xáµ¢ + b
y = f(z) [activation]

ğŸ”¹ Diagram
xâ‚ â”€â”€â—â”€â”€â”
xâ‚‚ â”€â”€â—â”€â”€â”¼â”€â–º â— â”€â”€â–º â— â”€â”€â–º Output
xâ‚ƒ â”€â”€â—â”€â”€â”˜     â—

UNIT V | Q3: SINGLE-LAYER VS MULTI-LAYER NN
Single-layer: no hidden layers; Multi-layer: â‰¥1 hidden layers.

| Aspect | Single-Layer | Multi-Layer |
|--------|--------------|-------------|
| Hidden Layers | None | One or more |
| Capability | Linear problems only | Non-linear problems |
| XOR Problem | Cannot solve | Can solve |
| Training | Simple rule | Backpropagation |

UNIT V | Q4: BACKPROPAGATION ALGORITHM
Trains multi-layer networks by propagating error backward to update weights.

ğŸ”¹ Steps (5 steps)
1. Forward pass: Compute output
2. Calculate error (MSE)
3. Backward pass: Propagate error
4. Compute gradients (âˆ‚E/âˆ‚w)
5. Update weights: wâ‚™â‚‘ğ“Œ = wâ‚’â‚—ğ’¹ - Î·Â·âˆ‚E/âˆ‚w

ğŸ”¹ Weight Update
w â† w - Î·Â·(âˆ‚E/âˆ‚w)

UNIT V | Q6: REINFORCEMENT LEARNING FRAMEWORK
Agent learns optimal behavior through environment interaction and rewards.

ğŸ”¹ Components (5 words)
Agent, environment, state, action, reward

ğŸ”¹ Interaction Cycle
State â†’ Action â†’ Reward â†’ New State

ğŸ”¹ Diagram
   Action (A)
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚              â–¼
Agent        Environment
 â–²              â”‚
 â”‚              â”‚
 â””â”€â”€ Reward (R) â”‚
   State (S) â”€â”€â”€â”˜

UNIT V | Q8: RL VS SUPERVISED/UNSUPERVISED LEARNING
RL learns via rewards; Supervised uses labels; Unsupervised finds patterns.

| Aspect | Supervised | Unsupervised | Reinforcement |
|--------|------------|--------------|---------------|
| Data | Labeled | Unlabeled | No labels |
| Feedback | Direct output | None | Rewards |
| Learning | From examples | Pattern discovery | Trial & error |
| Decision | Single-step | Single-step | Sequential |

UNIT V | Q9: Q-LEARNING ALGORITHM
Model-free RL algorithm learning optimal action-value function.

ğŸ”¹ Q-Table
Stores Q(s,a) values for state-action pairs

ğŸ”¹ Update Equation
Q(s,a) â† Q(s,a) + Î±[r + Î³Â·maxQ(s',a') - Q(s,a)]

ğŸ”¹ Parameters
Î± = Learning rate (0-1)
Î³ = Discount factor (0-1)

ğŸ”¹ Steps
1. Initialize Q-table
2. Observe state s
3. Choose action (Îµ-greedy)
4. Get reward r, next state s'
5. Update Q-value
6. Repeat until convergence
```
